# -*- coding: utf-8 -*-
"""FM2023

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qAyjRncn8WWE4qTaaC3iiVwvjCfBN-3e
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np


#CSV Dosya Yolu

dosya_yolu='/content/drive/MyDrive/LastFmData.csv'

#CSV Dosya Oku

df=pd.read_csv(dosya_yolu)
fm=df.copy()

"""Veri setimizi tanıtmadan önce aşşağıda kodumuzun işlevini anlatmak istiyoruz.Biz bu verisetimizi incelerken ve zorunlu olarak yaptığımız Web Scrabing yönteminden sonra çok fazla eksik değerler oldu ve
ileride de değineceğimiz üzere emekli olan ve çok değersiz futbolcuları verisetimizden temizledik.Fakat geriye kalan bir çok oyuncuyu tek tek elimizle girdik ve bu işlem çok uzun olduğu için
nasıl yaptığımızı aşşağıdaki kodda örnek olarak gösterip verisetimize aktardık.Böylece temiz bir veri setiyle işleme başlıyor gibi olduk.
"""

'''filtered_data = df[(df['Values'] > 180) ]

Yeni 'values' değerlerini klavyeden al ve güncelle
for index, row in filtered_data.iterrows():
    value = float(input(f"Yeni {row['Name']} ({row['Club']})'in değerini girin: "))
    df.loc[index, 'Values'] = value
    df.to_csv('/content/drive/MyDrive/CSV/LastFmData.csv', index=False)'''

"""**1)ÖNCELİKLE VERİ SETİMİZİ TANIYALIM.**

Verisetimizdeki Values adlı featurea 0-1 arasında normalize ettik ve yeni sütuna yazdırdık.
"""

from sklearn.preprocessing import MinMaxScaler

# MinMaxScaler nesnesini oluşturun
scaler = MinMaxScaler(feature_range=(0, 1))  # Ölçekleme aralığını [0, 1] olarak belirtin

# 'Values' sütununu ölçekleyin ve 'Normalized_Values' sütununa atayın
fm['Normalized_Values'] = scaler.fit_transform(fm[['Values']])

# 'Normalized_Values' sütununu yazdırın
print(fm['Normalized_Values'])

"""Veri setimizde çok fazla latin kökenli futbolcumuz olduğu için yazımlarda sorun oluyor bunu da aşşağıdaki kodumuz ile çözdük.

"""

!pip install unidecode

from unidecode import unidecode
def Convert_to_latin(string):
    return unidecode(string)

fm['Name'] = fm['Name'].apply(Convert_to_latin)

print(fm)

fm.head(5)

fm.info()

fm.describe()

"""*Bizim amacımız geleceği parlak oyuncuları bulmak.Ve biz bunları özellikleri üzerinden bulacağız.Bu yüzden gereksiz olan sütunları verisetimizden kaldırabiliriz.(Örn:Rental Club)*

"""

istenmeyen_sutun2="Rental club"
fm=fm.drop(istenmeyen_sutun2,axis=1)

fm.info()

"""!!!!-Veri setimizde ek olarak "VALUES" yani futbolcularımızın değerleri oyundaki fiyatlara göre olduğundan bize zorluk çıkartıyordu.Bunun için WEB SCRABING yöntemi ile Transfermarkt adlı siteden oyuncuların güncel değerlerini aldık.(Web scrabing yöntemi 3-4 saat sürdüğü için bu işlemi yapıp comment-out şeklinde size göstermek istedik.)"""

''' import re
import requests
from bs4 import BeautifulSoup
import pandas as pd , numpy as np
import plotly.express as px
!pip install unidecode
from unidecode import unidecode


headers={
    "User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"

}



def Convert_to_latin(string):
    return unidecode(string)

def Find_Player_Url(player_name):
    search_url = f"https://www.transfermarkt.com/schnellsuche/ergebnis/schnellsuche?query={player_name}&x=0&y=0"

    # Headers tanımlama
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'
    }

    try:
        response = requests.get(search_url, headers=headers)

        if response.status_code == 200:
            html_content = response.content
            soup = BeautifulSoup(html_content, 'html.parser')

            # Oyuncu adına göre ilk sonuçtan URL'yi çıkartma
            player_link = soup.find('a', {'title': player_name})

            if player_link:
                player_url = player_link['href']
                full_url = f"https://www.transfermarkt.com{player_url}"
                return full_url
            else:
                # Oyuncu bağlantısı bulunamadı, Latin alfabesine çevrilmiş oyuncu adı ile tekrar dene
                latin_player_name = Convert_to_latin(player_name)
                if latin_player_name != player_name:
                    return Find_Player_Url(latin_player_name)
                else:
                    print("Oyuncu bağlantısı bulunamadı.")
        else:
            print(f"HTTP Hatası: {response.status_code}")
    except Exception as e:
        print(f"Hata oluştu: {e}")




def Get_Market_Value(player_name):

    url = Find_Player_Url(player_name)

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'
    }
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.content, "html.parser")

    market_value_element = soup.find('a', class_='data-header__market-value-wrapper')

    if market_value_element:
        market_value_text = market_value_element.text.strip()
        numeric_part = re.search(r'\d+\.\d+|\d+', market_value_text)
        market_value = float(numeric_part.group()) if numeric_part else None
        return market_value
    else:
        return 0

fm['Values'] = fm['Values'].astype(float)
fm.info()

hatasayacı=0

for satir_indeksi, satir in df.iterrows():

    try:

        # Her satır için bir işlem yapalım (örneğin, Name ve Values sütunlarını yazdıralım)
        sutun_adi = 'Values'
        istenen_deger = Get_Market_Value(fm.iloc[satir_indeksi]["Name"])  # Değiştirmek istediğiniz yeni değer
        if(istenen_deger>181):
          istenen_deger=istenen_deger/1000


        fm.at[satir_indeksi, sutun_adi] = istenen_deger
        print(str(fm.iloc[satir_indeksi]["Name"]) +" " +str(fm.iloc[satir_indeksi]["Values"]))


        fm.to_csv('/content/drive/MyDrive/CSV/fmValues.csv', index=False)


    except Exception as e:
        print("Hata:", e)
        print("Hata Alınan index değeri"+str(satir_indeksi))
        print(hatasayacı)
        hatasayacı+=1
        continue  # Hata alındığında döngüyü sonraki satıra geçerek devam ettir

print("Döngü tamamlandı.")


'''

#sifir_oyuncular = fm[fm['Values'] == 0]
#print(sifir_oyuncular)

#fm = fm[fm['Values'] != 0]
#print(fm)

fm = fm.drop(fm[fm['Values'] == 0].index).reset_index(drop=True)
print(fm)

"""Bu yukarıdaki kodumuzda Values değerleri "0" olan oyuncuları sildik.Çünkü değeri "0" olan futbolcular ya emekli ya da çok alt ligde olan değerleri bilinmeyen futbolculardı.

İlerideki algoritmalarımızda kullanmak üzere hücum,ortasaha,defans,kaleci olmak üzere bu pozisyonlardaki oyuncular için gerekli görülen özellikleri ayrı ayrı verisetlerinde birleştiriyoruz.
"""

hucum_fm=fm[['Name','Age', 'Dribbling', 'Finishing', 'First Touch', 'Heading', 'Penalty Taking', 'Technique',
              'Flair',  'Agility', 'Balance', 'Jumping Reach', 'Pace', 'Stamina', 'Strength', 'Stability','Values','Normalized_Values','Position']]

hucum_fm = hucum_fm[hucum_fm['Position'].str.contains('S|AML|AMR')]

hucum_fm.head(50)

ortasaha_fm=fm[['Name','Age', 'Dribbling','Corners','Crossing','First Touch','Long Shots',
              'Passing','Technique','Vision','Decision','Agility','Balance','Stamina','Values','Normalized_Values','Position',]]

ortasaha_fm = ortasaha_fm[ortasaha_fm['Position'].str.contains('M|AM')]

ortasaha_fm.describe()

ortasaha_fm.head(50)

defans_fm=fm[['Name','Age','First Touch','Heading','Marking','Tackling','Jumping Reach','Strength',
              'Passing','Vision','Decision','Agility','Balance','Stamina','Values','Normalized_Values','Position',]]

defans_fm = defans_fm[defans_fm['Position'].str.contains('D')]

defans_fm.describe()

defans_fm.head(50)

kaleci_fm=fm[['Name','Age','Decision','Kicking','Handling','One On Ones','Reflexes','Rushing Out','Punching','Throwing','Values','Normalized_Values','Position',]]

kaleci_fm = kaleci_fm[kaleci_fm['Position'].str.contains('GK')]

kaleci_fm.describe()

kaleci_fm.head(5)

"""**2)VERİ SETİMİZİ GÖRSELLEŞTİRELİM**"""

import matplotlib.pyplot as plt


age=21
finishing=13

ulkeler_renkler = {'Türkiye': 'red', 'İspanya': 'blue', 'Fransa': 'green', 'Almanya': 'yellow'}  # Örnek renklendirme, dilediğiniz gibi güncelleyebilirsiniz


#Yaş sütunu 25'ten küçük ve bitiricilik sütunu 18'den fazla olan futbolcuları seç
filtrelenmis_veri = fm[(fm["Age"] < age) & (fm["Finishing"] > finishing)]

#Her bir ülkenin futbolcu sayısını hesapla
ulke_futbolcu_sayisi = filtrelenmis_veri.groupby('Nationality').size().sort_values(ascending=False)



#Renkli kutunun oluşturulması
fig, ax = plt.subplots(figsize=(14, 10))
for i, (ulke, futbolcu_sayisi) in enumerate(ulke_futbolcu_sayisi.items()):
    renk = np.random.rand(3,)  # Rastgele bir RGB renk oluşturur
    ax.barh(i, futbolcu_sayisi, color=renk, label=ulke)

#Eksenleri düzenleme
ax.set_yticks(np.arange(len(ulke_futbolcu_sayisi)))
ax.set_yticklabels(ulke_futbolcu_sayisi.index)
ax.invert_yaxis()  # Ülkeleri büyükten küçüğe doğru sıralamak için yönü tersine çevir

#Görsel ayarlamalar
plt.xlabel('Number of Players')
plt.ylabel('Country')
plt.title('Istenilen Özelliklere Göre Ülkerin Dagilimi')
plt.legend(title='Country', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(axis='x')
plt.show()

# Belirtilen özelliklerin ortalamasını almak için DataFrame'inizin adını ve özelliklerin adını belirtin
ortalamalar = hucum_fm[['Dribbling', 'Finishing', 'First Touch', 'Heading', 'Penalty Taking', 'Technique', 'Flair', 'Agility', 'Balance', 'Jumping Reach', 'Pace', 'Stamina', 'Strength', 'Stability']].mean()

# Ortalamaları görselleştirme
plt.figure(figsize=(10, 6))
ortalamalar.plot(kind='bar', color='cyan')
plt.title('Özelliklerin Ortalamaları')
plt.xlabel('Özellikler')
plt.ylabel('Ortalama')
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y')
plt.tight_layout()
plt.show()

"""İstediğimiz özellikteki futbolcunun yukarıda mevcut olan grafikte ortalamaların üstünde olmasına dikkat edeceğiz."""

galatasaray_value = fm[fm['Club'] == 'Galatasaray A.Ş.']['Values'].sum()
fenerbahce_value = fm[fm['Club'] == 'Fenerbahçe A.Ş.']['Values'].sum()
besiktas_value = fm[fm['Club'] == 'Beşiktaş A.Ş.']['Values'].sum()

club_values = fm.groupby('Club')['Values'].sum().reset_index()
top_clubs = club_values.nlargest(7, 'Values')


extra_clubs = ['Galatasaray A.Ş.', 'Fenerbahçe A.Ş.', 'Beşiktaş A.Ş.']
extra_values = [galatasaray_value, fenerbahce_value, besiktas_value]

plt.figure(figsize=(10, 6))
plt.bar(top_clubs['Club'], top_clubs['Values'], color='gold', label='Yabancı Kulüpler')
plt.bar(extra_clubs, extra_values, color='red', alpha=0.5, label='Türk Kulüpleri')  # Ekstra sütunlar
plt.title("En Değerli 7 Kulüp ve Galatasaray/Fenerbahçe/Beşiktaş")
plt.ylabel("Toplam Değer Milyon")
plt.xticks(rotation=45)
plt.legend()
plt.show()

# Nationality sütununa göre yaş ortalamasını hesaplayalım
age_mean_per_country = fm.groupby('Nationality')['Age'].mean().reset_index()

# En yüksek 10 ülkeyi seçelim
top_10_countries = age_mean_per_country.nlargest(20, 'Age')

# Çubuk grafik çizelim
plt.figure(figsize=(12, 6))
plt.bar(top_10_countries['Nationality'], top_10_countries['Age'], color='gray')
plt.title("En Yüksek 10 Ülkenin Ortalama Yaş Değerleri")
plt.xticks(rotation=45, ha='right')
plt.show()

fm['Nationality'].replace({'United States': 'United States of America'}, inplace=True)
fm['Nationality'].replace({'England': 'United Kingdom'}, inplace=True)
fm['Nationality'].replace({'Republic of Ireland': 'Ireland'}, inplace=True)
fm['Nationality'].replace({'China PR': 'China'}, inplace=True)

!pip install cartopy

import geopandas as gpd
import matplotlib.pyplot as plt

value = 15

# Ulke sınırları veri kümesini yükleyelim
world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))

# Eşik değerinin üzerindeki oyuncuları filtreleyelim
filtered_fm = fm[fm['Finishing'] >= value]

# Oyuncu sayısını her bir ülke için hesaplayalım
players_per_country = filtered_fm['Nationality'].value_counts().reset_index()
players_per_country.columns = ['Nationality', 'PlayerCount']

# Haritayı çizelim
fig, ax = plt.subplots(1, 1, figsize=(15, 10))
world.plot(ax=ax, color='lightgray', edgecolor='black')

# Ülkeleri oyuncu sayısına göre ısı haritası olarak renklendirelim
world.merge(players_per_country, how='left', left_on='name', right_on='Nationality').plot(column='PlayerCount', cmap='OrRd',linewidth=0.8, ax=ax, edgecolor='0.8',legend=True)
plt.title(f'Finishing Value >= {value}')
plt.show()

aim_value=10
# 'GK' pozisyonunda 10'dan fazla oyuncusu olanları seçme
gk = fm[fm['GK'] > aim_value]
total_gk = gk.shape[0]

# 'Defans' pozisyonunda 10'dan fazla oyuncusu olanları seçme
defence = fm[(fm['DL'] + fm['DC'] + fm['DR'] + fm['WBL'] + fm['WBR']) > aim_value]
total_defans = defence.shape[0]

# 'Ortasaha' pozisyonunda 10'dan fazla oyuncusu olanları seçme
midfield = fm[(fm['DM'] + fm['ML'] + fm['MC'] + fm['MR']) > aim_value]
total_midfield = midfield.shape[0]

# 'Forvet' pozisyonunda 10'dan fazla oyuncusu olanları seçme
forvet = fm[(fm['AML'] + fm['AMC'] + fm['AMR'] + fm['ST']) > aim_value]
total_forvet = forvet.shape[0]

# Grafik çizimi
plt.figure(figsize=(10, 6))

# Her pozisyon için çubuk grafikleri oluşturma
plt.bar('GK (Toplam)', total_gk, color='black', label='GK')
plt.bar('Defans (Toplam)', total_defans, color='magenta', label='Defans')
plt.bar('Ortasaha (Toplam)', total_midfield, color='cyan', label='Ortasaha')
plt.bar('Forvet (Toplam)', total_forvet, color='gray', label='Forvet')

plt.title(f'Toplam Oyuncu Sayısı - Pozisyonlarına Göre ({aim_value} Üzeri)')
plt.xlabel('Pozisyon')
plt.ylabel('Toplam Oyuncu Sayısı')
plt.legend()
plt.tight_layout()
plt.show()

# Milliyetlere göre kişi sayılarını hesaplamak
nationality_counts = fm['Nationality'].value_counts()

# Grafiği çizmek
plt.figure(figsize=(10, 6))
nationality_counts.head(10).plot(kind='bar', color='skyblue')
plt.title('Top 10 Oyuncu Sayısı')

plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""**3)ALGORİTMALARIMIZA BAŞLIYORUZ**"""

1from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.linear_model import ElasticNet
from sklearn.svm import SVR

# Modellerin ve isimlerin tanımlanması
models = {
    "Lasso Regression": Lasso(),
    "Decision Tree Regression": DecisionTreeRegressor(),
    "Random Forest Regression": RandomForestRegressor(),
    "XGBoost Regression": XGBRegressor(n_estimators=200, max_depth=3, learning_rate=0.1, min_child_weight=1,
                                        gamma=0, subsample=1, colsample_bytree=1),  # XGBoost için hiperparametreler
    "ElasticNet Regression": ElasticNet(),
    "SVR": SVR()
}

# X VE Y
X = hucum_fm.drop(['Name','Position', 'Values', 'Normalized_Values'], axis=1)
y = hucum_fm['Normalized_Values']

# Veri setini eğitim ve test setlerine ayırma
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Her bir model için eğitim ve tahmin işlemleri
for name, model in models.items():
    # Modelin eğitimi
    model.fit(X_train, y_train)

    # Tahminlerin yapılması
    y_pred = model.predict(X_test)

    # Hata hesaplaması
    mse = mean_squared_error(y_test, y_pred)

    print(f"Model: {name}")
    print("========================")
    print("Mean Squared Error (MSE):", mse)
    print("\n")

#Girdiğimiz inputlara göre oyuncunun Normalize Values'ini tahmin etme kodumuz:

from xgboost import plot_importance

'''
age=float(input("Age:"))
dribbling = float(input("Dribbling: "))
finishing = float(input("Finishing: "))
first_touch = float(input("First Touch: "))
heading = float(input("Heading: "))
penalty_taking = float(input("Penalty Taking: "))
technique = float(input("Technique: "))
flair = float(input("Flair: "))
agility = float(input("Agility: "))
balance = float(input("Balance: "))
jumping_reach = float(input("Jumping Reach: "))
pace = float(input("Pace: "))
stamina = float(input("Stamina: "))
strength = float(input("Strength: "))
stability = float(input("Stability: "))

input_features = [[age,dribbling, finishing, first_touch, heading, penalty_taking, technique, flair, agility, balance,
                   jumping_reach, pace, stamina, strength, stability]]

model =XGBRegressor(n_estimators=200, max_depth=3, learning_rate=0.1, min_child_weight=1,
                                        gamma=0, subsample=0.75, colsample_bytree=1)
model.fit(X, y)

predicted_value = model.predict(input_features)

original_value = predicted_value[0]*fm["Values"].max()

print("Tahmin edilen Values değeri:", predicted_value[0])
print("Orijinal Değer: ", original_value)

plot_importance(model, max_num_features=10)
plt.show()
'''

import pandas as pd
from xgboost import XGBRegressor
from xgboost import plot_importance
import matplotlib.pyplot as plt
from xgboost import plot_importance

# hucum_fm verisetini yükleyin


X = hucum_fm.drop(['Name','Position', 'Values', 'Normalized_Values'], axis=1)
y = hucum_fm['Normalized_Values']

model = XGBRegressor(n_estimators=200, max_depth=3, learning_rate=0.1, min_child_weight=1,
                     gamma=0, subsample=0.75, colsample_bytree=1)
model.fit(X, y)

for index, row in hucum_fm.iterrows():
    age = row['Age']
    dribbling = row['Dribbling']
    finishing = row['Finishing']
    first_touch = row['First Touch']
    heading = row['Heading']
    penalty_taking = row['Penalty Taking']
    technique = row['Technique']
    flair = row['Flair']
    agility = row['Agility']
    balance = row['Balance']
    jumping_reach = row['Jumping Reach']
    pace = row['Pace']
    stamina = row['Stamina']
    strength = row['Strength']
    stability = row['Stability']

    input_features = [[age, dribbling, finishing, first_touch, heading, penalty_taking, technique, flair, agility,
                       balance, jumping_reach, pace, stamina, strength, stability]]

    predicted_value = model.predict(input_features)

    original_value = predicted_value[0] * hucum_fm["Values"].max()

    hucum_fm.at[index, 'Predicted_Values'] = original_value

print(hucum_fm[['Values', 'Predicted_Values']])

plot_importance(model, max_num_features=10)
plt.show()

hucum_fm.head(20)

hucum_fm['Diff_Values'] = hucum_fm['Predicted_Values'] - hucum_fm['Values']

hucum_fm.head(20)

import pandas as pd
from xgboost import XGBRegressor
from xgboost import plot_importance
import matplotlib.pyplot as plt
from xgboost import plot_importance


X = ortasaha_fm.drop(['Name','Position', 'Values', 'Normalized_Values'], axis=1)
y = ortasaha_fm['Normalized_Values']

model = XGBRegressor(n_estimators=200, max_depth=3, learning_rate=0.1, min_child_weight=1,
                     gamma=0, subsample=0.75, colsample_bytree=1)
model.fit(X, y)

for index, row in ortasaha_fm.iterrows():
    age = row['Age']
    dribbling = row['Dribbling']
    corners = row['Corners']
    crossing = row['Crossing']
    first_touch = row['First Touch']
    long_shots = row['Long Shots']
    passing = row['Passing']
    technique = row['Technique']
    vision = row['Vision']
    decision = row['Decision']
    agility = row['Agility']
    balance = row['Balance']
    stamina = row['Stamina']

    input_features = [[age, dribbling, corners, crossing, first_touch, long_shots, passing, technique, vision,
                       decision, agility, balance, stamina]]

    predicted_value = model.predict(input_features)
    original_value = predicted_value[0] * fm["Values"].max()
    ortasaha_fm.at[index, 'Predicted_Values'] = original_value



plot_importance(model, max_num_features=10)
plt.show()

ortasaha_fm['Diff_Values'] = ortasaha_fm['Predicted_Values'] - ortasaha_fm['Values']
ortasaha_fm.head(20)

X = defans_fm.drop(['Name','Position', 'Values', 'Normalized_Values'], axis=1)
y = defans_fm['Normalized_Values']

model = XGBRegressor(n_estimators=200, max_depth=3, learning_rate=0.1, min_child_weight=1,
                     gamma=0, subsample=0.75, colsample_bytree=1)
model.fit(X, y)

for index, row in defans_fm.iterrows():
    age = row['Age']
    first_touch = row['First Touch']
    heading = row['Heading']
    marking = row['Marking']
    tackling = row['Tackling']
    jumping_reach = row['Jumping Reach']
    strength = row['Strength']
    passing = row['Passing']
    vision = row['Vision']
    decision = row['Decision']
    agility = row['Agility']
    balance = row['Balance']
    stamina = row['Stamina']

    input_features = [[age, first_touch, heading, marking, tackling, jumping_reach, strength, passing, vision,
                       decision, agility, balance, stamina]]

    predicted_value = model.predict(input_features)
    original_value = predicted_value[0] * fm["Values"].max()
    defans_fm.at[index, 'Predicted_Values'] = original_value



plot_importance(model, max_num_features=10)
plt.show()

defans_fm['Diff_Values'] = defans_fm['Predicted_Values'] - defans_fm['Values']
defans_fm.head(20)

X = kaleci_fm.drop(['Name','Position', 'Values', 'Normalized_Values'], axis=1)
y = kaleci_fm['Normalized_Values']

model = XGBRegressor(n_estimators=200, max_depth=3, learning_rate=0.1, min_child_weight=1,
                     gamma=0, subsample=0.75, colsample_bytree=1)
model.fit(X, y)

for index, row in kaleci_fm.iterrows():
    age = row['Age']
    decision = row['Decision']
    kicking = row['Kicking']
    handling = row['Handling']
    one_on_ones = row['One On Ones']
    reflexes = row['Reflexes']
    rushing_out = row['Rushing Out']
    punching = row['Punching']
    throwing = row['Throwing']

    input_features = [[age, decision, kicking, handling, one_on_ones, reflexes, rushing_out, punching, throwing]]

    predicted_value = model.predict(input_features)
    original_value = predicted_value[0] * fm["Values"].max()
    kaleci_fm.at[index, 'Predicted_Values'] = original_value



plot_importance(model, max_num_features=10)
plt.show()

kaleci_fm['Diff_Values'] = kaleci_fm['Predicted_Values'] - kaleci_fm['Values']
kaleci_fm.head(20)

sorted_df = kaleci_fm.sort_values(by='Diff_Values', ascending=False).head(20)
print(sorted_df)

sorted_df = defans_fm.sort_values(by='Diff_Values', ascending=False).head(20)
print(sorted_df)

sorted_df = ortasaha_fm.sort_values(by='Diff_Values', ascending=False).head(20)
print(sorted_df)

sorted_df = hucum_fm.sort_values(by='Diff_Values', ascending=False).head(20)
print(sorted_df)